{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Testing (latent) predRNN",
   "id": "8b1d7f6ce2792c68"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:43:03.118201Z",
     "start_time": "2025-06-27T15:43:03.112766Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Change working directory to be able to import predRNN packages without changing code\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "current_dir = Path(os.getcwd()).name\n",
    "if current_dir != 'predrnn':\n",
    "    os.chdir('./predrnn')\n",
    "    \n",
    "# PyTorch (related) imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from tqdm import trange\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else 'mps' if torch.mps.is_available() else \"cpu\")\n",
    "print(\"Torch device:\", device) # Quick check to see if we're using GPU or CPU.\n",
    "\n",
    "import random\n",
    "import optuna\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# PredRNN imports\n",
    "from argparse import Namespace\n",
    "from predrnn.core.models.model_factory import Model\n",
    "\n",
    "# Custom imports\n",
    "import dataset.download_and_preprocess as dl\n",
    "from dataset.dataloader import KTHDataset\n",
    "from autoencoder.autoencoder import AutoencoderModel\n",
    "\n",
    "# for reproducibility\n",
    "np.random.seed(42)"
   ],
   "id": "5c2bb4f7d04ad87a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Torch device: mps\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Configurations B)",
   "id": "88604ac2d8317973"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:39:43.990250Z",
     "start_time": "2025-06-27T15:39:43.977224Z"
    }
   },
   "cell_type": "code",
   "source": [
    "architectures = {\n",
    "    1: {\"encoder\" : nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), # 1x128x128-> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=1, padding=1), # 32x128x128 -> 16x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1), # 16x128x128 -> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 1, kernel_size=3, stride=1, padding=1), # 16x64x64 -> 1x64x64\n",
    "        ),\n",
    "        \"decoder\" : nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 16, kernel_size=3, stride=1, padding=1), # 1x64x64 -> 16x64x64 \n",
    "            nn.LeakyReLU(),\n",
    "            \n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=2, padding=1, output_padding=1), # 16x64x64 -> 16x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=1, padding=1), # 16x128x128 -> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=1, padding=1), # 32x128x128 -> 1x128x128\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        },\n",
    "\n",
    "    2: {\"encoder\" : nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), # 1x128x128 -> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1), # 32x128x128 -> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1), # 16x64x64-> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1), # 16x64x64 -> 8x32x32\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=1, padding=1), # 8x32x32-> 1x32x32\n",
    "        ),\n",
    "        \"decoder\" : nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 8, kernel_size=3, stride=1, padding=1), # 1x32x32-> 8x32x32\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1), # 8x32x32 -> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=1, padding=1), # 16x64x64 -> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1, output_padding=1), # 16x64x64-> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=1, padding=1), # 32x128x128 -> 1x128x128\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        },\n",
    "    3: {\"encoder\" : nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1), # 1x128x128 -> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(32, 16, kernel_size=3, stride=2, padding=1), # 32x128x128 -> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=1), # 1x128x128 -> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(16, 8, kernel_size=3, stride=2, padding=1), # 16x64x64 -> 8x32x32\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(8, 8, kernel_size=3, stride=1, padding=1), # 1x128x128 -> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.Conv2d(8, 1, kernel_size=3, stride=2, padding=1), # 8x32x32 -> 1x16x16\n",
    "        ),\n",
    "        \"decoder\" : nn.Sequential(\n",
    "            nn.ConvTranspose2d(1, 8, kernel_size=3, stride=2, padding=1, output_padding=1), # 1x16x16 -> 8x32x32\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(8, 8, kernel_size=3, stride=1, padding=1), # 8x32x32 -> 8x32x32\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(8, 16, kernel_size=3, stride=2, padding=1, output_padding=1), # 8x32x32 -> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 16, kernel_size=3, stride=1, padding=1), # 16x64x64 -> 16x64x64\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(16, 32, kernel_size=3, stride=2, padding=1, output_padding=1), # 16x64x64 -> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 32, kernel_size=3, stride=1, padding=1), # 32x128x128-> 32x128x128\n",
    "            nn.LeakyReLU(),\n",
    "\n",
    "            nn.ConvTranspose2d(32, 1, kernel_size=3, stride=1, padding=1), # 32x128x128 -> 1x128x128\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        }\n",
    "    \n",
    "}"
   ],
   "id": "50fdbdf6595f99b5",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:49:29.273803Z",
     "start_time": "2025-06-27T15:49:29.268828Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "base_configs_predRNN = {\n",
    "    'is_training': 1,\n",
    "    'device': device,\n",
    "    'model_name': 'predrnn_v2',\n",
    "    'visual': 0,\n",
    "    'reverse_input': 1,\n",
    "    'img_channel': 1,\n",
    "    'input_length': 10,\n",
    "    'total_length': 20,\n",
    "    'filter_size': 5,\n",
    "    'stride': 1,\n",
    "    'patch_size': 4,\n",
    "    'layer_norm': 0,\n",
    "    'decouple_beta': 0.01,\n",
    "    'reverse_scheduled_sampling': 1,\n",
    "    'r_sampling_step_1': 5000,\n",
    "    'r_sampling_step_2': 50000,\n",
    "    'r_exp_alpha': 2000,\n",
    "    'lr': 0.0001,\n",
    "    'batch_size': 4,\n",
    "    'max_iterations': 500,\n",
    "    'display_interval': 100,\n",
    "    # 'test_interval': 500,\n",
    "    'snapshot_interval': 100,\n",
    "    'visual_path': './decoupling_visual',\n",
    "    # 'pretrained_model': './checkpoints/kth_predrnn_v2/kth_model.ckpt'  # Uncomment if needed\n",
    "}"
   ],
   "id": "29c3a77648c30b70",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "root_path = '/Users/maxneerken/Documents/aml/predrnn-pytorch-AML'",
   "id": "a5234aac00ff117e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T15:49:26.534071Z",
     "start_time": "2025-06-27T15:49:26.530858Z"
    }
   },
   "cell_type": "code",
   "source": [
    "latent_16_predrnn_configs = {\n",
    "    'dataset_name': 'latent',\n",
    "    'train_data_paths': f'{root_path}/dataset/encoded/16',\n",
    "    'valid_data_paths': f'{root_path}/dataset/encoded/16',\n",
    "    'save_dir': 'checkpoints/latent_16/kth_predrnn_v2',\n",
    "    'gen_frm_dir': 'results/latent_16_kth_predrnn_v2',\n",
    "    'img_width': 16,\n",
    "    'num_hidden': '16, 16, 16, 16',  # Using a tuple for multiple values\n",
    "}\n",
    "\n",
    "latent_32_predrnn_configs = {\n",
    "    'dataset_name': 'latent',\n",
    "    'train_data_paths': f'{root_path}/dataset/encoded/32',\n",
    "    'valid_data_paths': f'{root_path}/dataset/encoded/32',\n",
    "    'save_dir': 'checkpoints/latent_32/kth_predrnn_v2',\n",
    "    'gen_frm_dir': 'results/latent_32_kth_predrnn_v2',\n",
    "    'img_width': 32,\n",
    "    'num_hidden': '32, 32, 32, 32',  # Using a tuple for multiple values\n",
    "}\n",
    "\n",
    "latent_64_predrnn_configs = {\n",
    "    'dataset_name': 'latent',\n",
    "    'train_data_paths': f'{root_path}/dataset/encoded/64',\n",
    "    'valid_data_paths': f'{root_path}/dataset/encoded/64',\n",
    "    'save_dir': 'checkpoints/latent_64/kth_predrnn_v2',\n",
    "    'gen_frm_dir': 'results/latent_64_kth_predrnn_v2',\n",
    "    'img_width': 64,\n",
    "    'num_hidden': '64, 64, 64, 64',  # Using a tuple for multiple values\n",
    "}"
   ],
   "id": "9163f99eeeec3d22",
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Start evaluating :O",
   "id": "69980cb394dab407"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-27T15:51:43.919429Z",
     "start_time": "2025-06-27T15:51:43.884541Z"
    }
   },
   "source": [
    "args = Namespace(**(base_configs_predRNN | latent_16_predrnn_configs))\n",
    "\n",
    "model = Model(args)\n",
    "model.load('./checkpoints/latent_16/kth_predrnn_v2/model.ckpt-4')\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model: ./checkpoints/latent_16/kth_predrnn_v2/model.ckpt-4\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-27T16:00:19.073879Z",
     "start_time": "2025-06-27T16:00:19.067078Z"
    }
   },
   "cell_type": "code",
   "source": "model.network",
   "id": "4ad53c2fccd558a5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (MSE_criterion): MSELoss()\n",
       "  (cell_list): ModuleList(\n",
       "    (0-3): 4 x SpatioTemporalLSTMCell(\n",
       "      (conv_x): Sequential(\n",
       "        (0): Conv2d(16, 112, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_h): Sequential(\n",
       "        (0): Conv2d(16, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_m): Sequential(\n",
       "        (0): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_o): Sequential(\n",
       "        (0): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      )\n",
       "      (conv_last): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    )\n",
       "  )\n",
       "  (conv_last): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (adapter): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
